{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from feature_engine.selection import DropCorrelatedFeatures\n",
    "import joblib\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_weight parametresine şunlar atanabilir:\n",
    "\n",
    "None: Bütün sınıflar eşit ağırlığa sahip olur. Bu varsayılan değerdir.\n",
    "'balanced': Sınıfların frekanslarına göre otomatik olarak ağırlık atanır. Ağırlıklar, n_samples / (n_classes * np.bincount(y)) formülü ile hesaplanır. Burada n_samples toplam örnek sayısıdır ve np.bincount(y) ise her sınıftaki örnek sayısını verir.\n",
    "{sınıf_etiketi: ağırlık}: Bu, sınıflar için elle ağırlık belirtmenize olanak tanır. Örneğin, iki sınıflı bir problem için {0: 1, 1: 50} şeklinde bir sözlük belirtilebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_cols(df):\n",
    "    num_cols = list(df.select_dtypes(include=\"number\"))\n",
    "    cat_cols = [col for col in df.columns if col not in num_cols]\n",
    "    num_but_cat = [col for col in num_cols if df[col].nunique()<10]\n",
    "    cat_but_car = [col for col in cat_cols if df[col].nunique() >20]\n",
    "    cat_cols = cat_cols + num_but_cat \n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "    print(f\"cat_cols = {len(cat_cols)}\")\n",
    "    print(f\"num_cols = {len(num_cols)}\")\n",
    "    print(f\"num_but_cat = {len(num_but_cat)}\")\n",
    "    print(f\"cat_but_car= {len(cat_but_car)}\")\n",
    "    return cat_cols,num_cols,cat_but_car,num_but_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cagat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\impute\\_iterative.py:796: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_cols = 4\n",
      "num_cols = 8\n",
      "num_but_cat = 1\n",
      "cat_but_car= 0\n"
     ]
    }
   ],
   "source": [
    "def diabetes_data_prep():\n",
    "    df = pd.read_csv(\"diabetes.csv\")\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    X = df.drop(\"outcome\",axis=1)\n",
    "    y =df[\"outcome\"]\n",
    "    cols=[\"glucose\",\"bloodpressure\",\"skinthickness\",\"insulin\",\"bmi\"]\n",
    "\n",
    "    for col in cols:\n",
    "        X.loc[X[col]==0,col] = np.nan\n",
    "    def outliers(df,variable):\n",
    "        q1= df[variable].quantile(0.2)\n",
    "        q3 = df[variable].quantile(0.8)\n",
    "        iqr = q3 - q1\n",
    "        lower_lim = q1 - 1.5*iqr\n",
    "        upper_lim = q3 + 1.5*iqr\n",
    "        return lower_lim,upper_lim\n",
    "\n",
    "    def replace_outliers(X,col):\n",
    "        lower_lim,upper_lim = outliers(X,col)\n",
    "        X[col].clip(lower=lower_lim,upper=upper_lim,inplace=True)\n",
    "\n",
    "    replace_outliers(X,\"insulin\")\n",
    "    imp_missforest = IterativeImputer(\n",
    "    estimator=XGBRegressor(n_estimators=300,max_depth=5),\n",
    "    max_iter=30,\n",
    "    initial_strategy=\"median\",\n",
    "    random_state=0\n",
    "    ).set_output(transform=\"pandas\")\n",
    "\n",
    "    X=imp_missforest.fit_transform(X)\n",
    "    def ohe(dataframe,cat_cols):\n",
    "        dataframe = pd.get_dummies(dataframe,columns=cat_cols,drop_first=True,dtype=int)\n",
    "        return dataframe\n",
    "    X[\"new_glucose_cat\"] = pd.cut(x=X[\"glucose\"],bins=[-1,100,140,200],labels=[\"normal\",\"prediabetes\",\"danger\"])\n",
    "\n",
    "    X.loc[X[\"age\"]<32,\"new_age_cat\"] = 0\n",
    "    X.loc[(X[\"age\"]>=32) & (X[\"age\"]<=50),\"new_age_cat\"]= 1\n",
    "    X.loc[X[\"age\"]>50,\"new_age_cat\"] =2\n",
    "\n",
    "    # X[\"new_age2\"] = pd.cut(x=X[\"age\"],bins=[-1,32,50,100],labels= [0,1,2]) # alt sınıfa dahil eder\n",
    "\n",
    "    X[\"new_bmi\"] = pd.cut(x=X[\"bmi\"],bins=[-1,18.5,24.9,29.9,100],labels=[\"underweight\",\"healthy\",\"overweight\",\"obese\"])\n",
    "    X[\"new_bloodpressure\"] = pd.cut(x=X[\"bloodpressure\"],bins=[-1,79,89,123],labels=[\"normal\",\"hs1\",\"hs2\"])\n",
    "    \n",
    "    cat_cols,num_cols,cat_but_car,num_but_cat = grab_cols(X)\n",
    "    X=ohe(X,cat_cols)\n",
    "    lof = LocalOutlierFactor(n_neighbors=10,n_jobs=-1)\n",
    "    lof.fit_predict(X)\n",
    "    X_scores = lof.negative_outlier_factor_\n",
    "    df = pd.concat([X,y],axis=1)\n",
    "    df=df.drop(labels =list(df[X_scores<-1.8].index),axis=0 )\n",
    "    X=df.drop(\"outcome\",axis=1)\n",
    "    y = df[\"outcome\"]\n",
    "    sc = StandardScaler().set_output(transform=\"pandas\")\n",
    "    X = sc.fit_transform(X)\n",
    "    return X,y\n",
    "X,y = diabetes_data_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7804843304843305"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight='balanced')\n",
    "cross_val_score(lr,X,y,cv=10,n_jobs=-1,scoring=\"recall\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.841465724751439"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr,X,y,cv=10,n_jobs=-1,scoring=\"roc_auc\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7618421052631579"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr,X,y,cv=10,n_jobs=-1,scoring=\"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7652421652421653"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced',n_estimators=200,max_depth=4)\n",
    "cross_val_score(rf,X,y,cv=10,n_jobs=-1,scoring=\"recall\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8434630501773359"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf,X,y,cv=10,n_jobs=-1,scoring=\"roc_auc\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bloodpressure</th>\n",
       "      <th>skinthickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diabetespedigreefunction</th>\n",
       "      <th>age</th>\n",
       "      <th>new_glucose_cat_prediabetes</th>\n",
       "      <th>new_glucose_cat_danger</th>\n",
       "      <th>new_bmi_healthy</th>\n",
       "      <th>new_bmi_overweight</th>\n",
       "      <th>new_bmi_obese</th>\n",
       "      <th>new_bloodpressure_hs1</th>\n",
       "      <th>new_bloodpressure_hs2</th>\n",
       "      <th>new_age_cat_1.0</th>\n",
       "      <th>new_age_cat_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.633702</td>\n",
       "      <td>0.869437</td>\n",
       "      <td>-0.036565</td>\n",
       "      <td>0.667253</td>\n",
       "      <td>0.070035</td>\n",
       "      <td>0.186704</td>\n",
       "      <td>0.485557</td>\n",
       "      <td>1.458321</td>\n",
       "      <td>-0.953702</td>\n",
       "      <td>1.725995</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>-0.557086</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>1.445486</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.851843</td>\n",
       "      <td>-1.208138</td>\n",
       "      <td>-0.544486</td>\n",
       "      <td>0.030784</td>\n",
       "      <td>-0.675924</td>\n",
       "      <td>-0.864077</td>\n",
       "      <td>-0.363975</td>\n",
       "      <td>-0.186077</td>\n",
       "      <td>-0.953702</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>1.795055</td>\n",
       "      <td>-1.290994</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>-0.691809</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.227920</td>\n",
       "      <td>2.023646</td>\n",
       "      <td>-0.713794</td>\n",
       "      <td>-0.954370</td>\n",
       "      <td>0.744538</td>\n",
       "      <td>-1.359445</td>\n",
       "      <td>0.624067</td>\n",
       "      <td>-0.099529</td>\n",
       "      <td>-0.953702</td>\n",
       "      <td>1.725995</td>\n",
       "      <td>2.554360</td>\n",
       "      <td>-0.557086</td>\n",
       "      <td>-1.290994</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>1.445486</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.851843</td>\n",
       "      <td>-1.076228</td>\n",
       "      <td>-0.544486</td>\n",
       "      <td>-0.605686</td>\n",
       "      <td>-0.637236</td>\n",
       "      <td>-0.638909</td>\n",
       "      <td>-0.930330</td>\n",
       "      <td>-1.051549</td>\n",
       "      <td>-0.953702</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>1.795055</td>\n",
       "      <td>-1.290994</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>-0.691809</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.148952</td>\n",
       "      <td>0.506686</td>\n",
       "      <td>-2.745481</td>\n",
       "      <td>0.667253</td>\n",
       "      <td>0.223966</td>\n",
       "      <td>1.612764</td>\n",
       "      <td>5.598139</td>\n",
       "      <td>-0.012982</td>\n",
       "      <td>1.048545</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>-0.557086</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>1.445486</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>1.822138</td>\n",
       "      <td>-0.680500</td>\n",
       "      <td>0.302050</td>\n",
       "      <td>2.046271</td>\n",
       "      <td>0.363620</td>\n",
       "      <td>0.081626</td>\n",
       "      <td>-0.918018</td>\n",
       "      <td>2.583435</td>\n",
       "      <td>1.048545</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>-0.557086</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>-0.691809</td>\n",
       "      <td>2.956956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-0.554734</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>-0.205872</td>\n",
       "      <td>-0.181373</td>\n",
       "      <td>0.500327</td>\n",
       "      <td>0.667061</td>\n",
       "      <td>-0.397833</td>\n",
       "      <td>-0.532265</td>\n",
       "      <td>1.048545</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>-0.557086</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>-0.691809</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.336593</td>\n",
       "      <td>-0.020952</td>\n",
       "      <td>-0.036565</td>\n",
       "      <td>-0.605686</td>\n",
       "      <td>-0.427754</td>\n",
       "      <td>-0.924121</td>\n",
       "      <td>-0.690245</td>\n",
       "      <td>-0.272624</td>\n",
       "      <td>1.048545</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>1.795055</td>\n",
       "      <td>-1.290994</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>-0.691809</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-0.851843</td>\n",
       "      <td>0.143935</td>\n",
       "      <td>-1.052408</td>\n",
       "      <td>0.025221</td>\n",
       "      <td>-0.286800</td>\n",
       "      <td>-0.338686</td>\n",
       "      <td>-0.370131</td>\n",
       "      <td>1.198679</td>\n",
       "      <td>1.048545</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>-0.557086</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>1.445486</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-0.851843</td>\n",
       "      <td>-0.944319</td>\n",
       "      <td>-0.205872</td>\n",
       "      <td>0.242940</td>\n",
       "      <td>-0.900446</td>\n",
       "      <td>-0.293653</td>\n",
       "      <td>-0.474784</td>\n",
       "      <td>-0.878454</td>\n",
       "      <td>-0.953702</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>-0.557086</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>-0.691809</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnancies   glucose  bloodpressure  skinthickness   insulin       bmi  \\\n",
       "0       0.633702  0.869437      -0.036565       0.667253  0.070035  0.186704   \n",
       "1      -0.851843 -1.208138      -0.544486       0.030784 -0.675924 -0.864077   \n",
       "2       1.227920  2.023646      -0.713794      -0.954370  0.744538 -1.359445   \n",
       "3      -0.851843 -1.076228      -0.544486      -0.605686 -0.637236 -0.638909   \n",
       "4      -1.148952  0.506686      -2.745481       0.667253  0.223966  1.612764   \n",
       "..           ...       ...            ...            ...       ...       ...   \n",
       "763     1.822138 -0.680500       0.302050       2.046271  0.363620  0.081626   \n",
       "764    -0.554734  0.012025      -0.205872      -0.181373  0.500327  0.667061   \n",
       "765     0.336593 -0.020952      -0.036565      -0.605686 -0.427754 -0.924121   \n",
       "766    -0.851843  0.143935      -1.052408       0.025221 -0.286800 -0.338686   \n",
       "767    -0.851843 -0.944319      -0.205872       0.242940 -0.900446 -0.293653   \n",
       "\n",
       "     diabetespedigreefunction       age  new_glucose_cat_prediabetes  \\\n",
       "0                    0.485557  1.458321                    -0.953702   \n",
       "1                   -0.363975 -0.186077                    -0.953702   \n",
       "2                    0.624067 -0.099529                    -0.953702   \n",
       "3                   -0.930330 -1.051549                    -0.953702   \n",
       "4                    5.598139 -0.012982                     1.048545   \n",
       "..                        ...       ...                          ...   \n",
       "763                 -0.918018  2.583435                     1.048545   \n",
       "764                 -0.397833 -0.532265                     1.048545   \n",
       "765                 -0.690245 -0.272624                     1.048545   \n",
       "766                 -0.370131  1.198679                     1.048545   \n",
       "767                 -0.474784 -0.878454                    -0.953702   \n",
       "\n",
       "     new_glucose_cat_danger  new_bmi_healthy  new_bmi_overweight  \\\n",
       "0                  1.725995        -0.391488           -0.557086   \n",
       "1                 -0.579376        -0.391488            1.795055   \n",
       "2                  1.725995         2.554360           -0.557086   \n",
       "3                 -0.579376        -0.391488            1.795055   \n",
       "4                 -0.579376        -0.391488           -0.557086   \n",
       "..                      ...              ...                 ...   \n",
       "763               -0.579376        -0.391488           -0.557086   \n",
       "764               -0.579376        -0.391488           -0.557086   \n",
       "765               -0.579376        -0.391488            1.795055   \n",
       "766               -0.579376        -0.391488           -0.557086   \n",
       "767               -0.579376        -0.391488           -0.557086   \n",
       "\n",
       "     new_bmi_obese  new_bloodpressure_hs1  new_bloodpressure_hs2  \\\n",
       "0         0.774597              -0.497943              -0.290113   \n",
       "1        -1.290994              -0.497943              -0.290113   \n",
       "2        -1.290994              -0.497943              -0.290113   \n",
       "3        -1.290994              -0.497943              -0.290113   \n",
       "4         0.774597              -0.497943              -0.290113   \n",
       "..             ...                    ...                    ...   \n",
       "763       0.774597              -0.497943              -0.290113   \n",
       "764       0.774597              -0.497943              -0.290113   \n",
       "765      -1.290994              -0.497943              -0.290113   \n",
       "766       0.774597              -0.497943              -0.290113   \n",
       "767       0.774597              -0.497943              -0.290113   \n",
       "\n",
       "     new_age_cat_1.0  new_age_cat_2.0  \n",
       "0           1.445486        -0.338186  \n",
       "1          -0.691809        -0.338186  \n",
       "2           1.445486        -0.338186  \n",
       "3          -0.691809        -0.338186  \n",
       "4           1.445486        -0.338186  \n",
       "..               ...              ...  \n",
       "763        -0.691809         2.956956  \n",
       "764        -0.691809        -0.338186  \n",
       "765        -0.691809        -0.338186  \n",
       "766         1.445486        -0.338186  \n",
       "767        -0.691809        -0.338186  \n",
       "\n",
       "[760 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.878787878787879"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "496/264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameter optimization\n",
      "##### rf######\n",
      "roc_auc (Before): 0.8283322286179429\n",
      "roc_auc (After): 0.8426249200534913\n",
      "rf best_params: {'max_depth': 5, 'min_samples_split': 15, 'n_estimators': 300}\n",
      "\n",
      "##### xgb######\n",
      "roc_auc (Before): 0.789438862724577\n",
      "roc_auc (After): 0.8463807779522066\n",
      "xgb best_params: {'booster': 'gblinear', 'n_estimators': 200, 'reg_alpha': 0.01, 'reg_lambda': 0.05}\n",
      "\n",
      "##### lr######\n",
      "roc_auc (Before): 0.841388801674516\n",
      "roc_auc (After): 0.8460824466538753\n",
      "lr best_params: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l1'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_params={\"max_depth\":[3,4,5,6], \n",
    "           \"min_samples_split\":[15,20],\n",
    "           \"n_estimators\":[200,300]}\n",
    "\n",
    "xgb_params = {\"booster\":[\"gblinear\",\"gbtree\"],\n",
    "              \"n_estimators\":[200,300],\n",
    "              \"reg_lambda\":[0.02,0.05],\n",
    "              \"reg_alpha\":[0.01,0.02]}\n",
    "\n",
    "lr_params = {'C': [0.01, 0.1, 1, 10],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            \"max_iter\":[5000,1000]}\n",
    "\n",
    "\n",
    "classifiers = [(\"rf\",RandomForestClassifier(class_weight='balanced'),rf_params),\n",
    "               (\"xgb\",XGBClassifier(objective =\"binary:logistic\",scale_pos_weight=1.88),xgb_params),\n",
    "               (\"lr\",LogisticRegression(solver='liblinear',class_weight='balanced'),lr_params)]\n",
    "\n",
    "def hyperparameter_optimization(X,y,scoring=\"roc_auc\"):\n",
    "    print(\"hyperparameter optimization\")\n",
    "    best_models ={}\n",
    "    for name,classifier,params in classifiers:\n",
    "        print(f\"##### {name}######\")\n",
    "        cv_results = cross_val_score(classifier,X,y,scoring=scoring,cv=10,n_jobs=-1).mean()\n",
    "        print(f\"{scoring} (Before): {cv_results}\")\n",
    "        \n",
    "        gs = GridSearchCV(classifier,params,cv=10,scoring=scoring).fit(X,y)\n",
    "        final_model = classifier.set_params(**gs.best_params_)\n",
    "        \n",
    "        cv_results = cross_val_score(final_model,X,y,scoring=scoring,cv=10,n_jobs=-1).mean()\n",
    "        print(f\"{scoring} (After): {cv_results}\")\n",
    "        print(f\"{name} best_params: {gs.best_params_}\", end=\"\\n\\n\")\n",
    "        best_models[name] = final_model\n",
    "    return best_models\n",
    "    \n",
    "best_models = hyperparameter_optimization(X,y,scoring=\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf': RandomForestClassifier(class_weight='balanced', max_depth=5,\n",
       "                        min_samples_split=15, n_estimators=300),\n",
       " 'xgb': XGBClassifier(base_score=None, booster='gblinear', callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "               gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
       "               predictor=None, random_state=None, ...),\n",
       " 'lr': LogisticRegression(C=0.1, class_weight='balanced', max_iter=1000, penalty='l1',\n",
       "                    solver='liblinear')}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8499018547589976"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators = [(\"lr\",best_models[\"lr\"]),\n",
    "                                            (\"rf\",best_models[\"rf\"]),\n",
    "                                            (\"xg\",best_models[\"xgb\"])],\n",
    "                              voting='soft',\n",
    "                            weights=[1,1,1])\n",
    "\n",
    "cross_val_score(voting_clf,X,y,cv=10,n_jobs=-1,scoring=\"roc_auc\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7776315789473685"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(voting_clf,X,y,cv=10,n_jobs=-1,scoring=\"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7749999999999999"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators = [(\"lr\",best_models[\"lr\"]),\n",
    "                                            (\"rf\",best_models[\"rf\"]),\n",
    "                                            (\"xg\",best_models[\"xgb\"])],\n",
    "                              voting='hard')\n",
    "\n",
    "cross_val_score(voting_clf,X,y,cv=10,n_jobs=-1,scoring=\"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7776315789473685"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "xg = XGBClassifier(n_estimators=100,booster=\"gblinear\",reg_lambda=0.02,reg_alpha=0.01,objective =\"binary:logistic\")\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', lr), ('xg', xg)],\n",
    "    voting='soft',\n",
    "    weights=[4,1]  # Ağırlıkları belirtiyoruz\n",
    ")\n",
    "cross_val_score(voting_clf,X,y,cv=10,n_jobs=-1,scoring=\"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bloodpressure</th>\n",
       "      <th>skinthickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diabetespedigreefunction</th>\n",
       "      <th>age</th>\n",
       "      <th>new_glucose_cat_prediabetes</th>\n",
       "      <th>new_glucose_cat_danger</th>\n",
       "      <th>new_bmi_healthy</th>\n",
       "      <th>new_bmi_overweight</th>\n",
       "      <th>new_bmi_obese</th>\n",
       "      <th>new_bloodpressure_hs1</th>\n",
       "      <th>new_bloodpressure_hs2</th>\n",
       "      <th>new_age_cat_1.0</th>\n",
       "      <th>new_age_cat_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.633702</td>\n",
       "      <td>0.869437</td>\n",
       "      <td>-0.036565</td>\n",
       "      <td>0.667253</td>\n",
       "      <td>0.070035</td>\n",
       "      <td>0.186704</td>\n",
       "      <td>0.485557</td>\n",
       "      <td>1.458321</td>\n",
       "      <td>-0.953702</td>\n",
       "      <td>1.725995</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>-0.557086</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>1.445486</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.851843</td>\n",
       "      <td>-1.208138</td>\n",
       "      <td>-0.544486</td>\n",
       "      <td>0.030784</td>\n",
       "      <td>-0.675924</td>\n",
       "      <td>-0.864077</td>\n",
       "      <td>-0.363975</td>\n",
       "      <td>-0.186077</td>\n",
       "      <td>-0.953702</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>1.795055</td>\n",
       "      <td>-1.290994</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>-0.691809</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.227920</td>\n",
       "      <td>2.023646</td>\n",
       "      <td>-0.713794</td>\n",
       "      <td>-0.954370</td>\n",
       "      <td>0.744538</td>\n",
       "      <td>-1.359445</td>\n",
       "      <td>0.624067</td>\n",
       "      <td>-0.099529</td>\n",
       "      <td>-0.953702</td>\n",
       "      <td>1.725995</td>\n",
       "      <td>2.554360</td>\n",
       "      <td>-0.557086</td>\n",
       "      <td>-1.290994</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>1.445486</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.851843</td>\n",
       "      <td>-1.076228</td>\n",
       "      <td>-0.544486</td>\n",
       "      <td>-0.605686</td>\n",
       "      <td>-0.637236</td>\n",
       "      <td>-0.638909</td>\n",
       "      <td>-0.930330</td>\n",
       "      <td>-1.051549</td>\n",
       "      <td>-0.953702</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>1.795055</td>\n",
       "      <td>-1.290994</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>-0.691809</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.148952</td>\n",
       "      <td>0.506686</td>\n",
       "      <td>-2.745481</td>\n",
       "      <td>0.667253</td>\n",
       "      <td>0.223966</td>\n",
       "      <td>1.612764</td>\n",
       "      <td>5.598139</td>\n",
       "      <td>-0.012982</td>\n",
       "      <td>1.048545</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>-0.557086</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>1.445486</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>1.822138</td>\n",
       "      <td>-0.680500</td>\n",
       "      <td>0.302050</td>\n",
       "      <td>2.046271</td>\n",
       "      <td>0.363620</td>\n",
       "      <td>0.081626</td>\n",
       "      <td>-0.918018</td>\n",
       "      <td>2.583435</td>\n",
       "      <td>1.048545</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>-0.557086</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>-0.691809</td>\n",
       "      <td>2.956956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-0.554734</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>-0.205872</td>\n",
       "      <td>-0.181373</td>\n",
       "      <td>0.500327</td>\n",
       "      <td>0.667061</td>\n",
       "      <td>-0.397833</td>\n",
       "      <td>-0.532265</td>\n",
       "      <td>1.048545</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>-0.557086</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>-0.691809</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.336593</td>\n",
       "      <td>-0.020952</td>\n",
       "      <td>-0.036565</td>\n",
       "      <td>-0.605686</td>\n",
       "      <td>-0.427754</td>\n",
       "      <td>-0.924121</td>\n",
       "      <td>-0.690245</td>\n",
       "      <td>-0.272624</td>\n",
       "      <td>1.048545</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>1.795055</td>\n",
       "      <td>-1.290994</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>-0.691809</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-0.851843</td>\n",
       "      <td>0.143935</td>\n",
       "      <td>-1.052408</td>\n",
       "      <td>0.025221</td>\n",
       "      <td>-0.286800</td>\n",
       "      <td>-0.338686</td>\n",
       "      <td>-0.370131</td>\n",
       "      <td>1.198679</td>\n",
       "      <td>1.048545</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>-0.557086</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>1.445486</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-0.851843</td>\n",
       "      <td>-0.944319</td>\n",
       "      <td>-0.205872</td>\n",
       "      <td>0.242940</td>\n",
       "      <td>-0.900446</td>\n",
       "      <td>-0.293653</td>\n",
       "      <td>-0.474784</td>\n",
       "      <td>-0.878454</td>\n",
       "      <td>-0.953702</td>\n",
       "      <td>-0.579376</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>-0.557086</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>-0.497943</td>\n",
       "      <td>-0.290113</td>\n",
       "      <td>-0.691809</td>\n",
       "      <td>-0.338186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnancies   glucose  bloodpressure  skinthickness   insulin       bmi  \\\n",
       "0       0.633702  0.869437      -0.036565       0.667253  0.070035  0.186704   \n",
       "1      -0.851843 -1.208138      -0.544486       0.030784 -0.675924 -0.864077   \n",
       "2       1.227920  2.023646      -0.713794      -0.954370  0.744538 -1.359445   \n",
       "3      -0.851843 -1.076228      -0.544486      -0.605686 -0.637236 -0.638909   \n",
       "4      -1.148952  0.506686      -2.745481       0.667253  0.223966  1.612764   \n",
       "..           ...       ...            ...            ...       ...       ...   \n",
       "763     1.822138 -0.680500       0.302050       2.046271  0.363620  0.081626   \n",
       "764    -0.554734  0.012025      -0.205872      -0.181373  0.500327  0.667061   \n",
       "765     0.336593 -0.020952      -0.036565      -0.605686 -0.427754 -0.924121   \n",
       "766    -0.851843  0.143935      -1.052408       0.025221 -0.286800 -0.338686   \n",
       "767    -0.851843 -0.944319      -0.205872       0.242940 -0.900446 -0.293653   \n",
       "\n",
       "     diabetespedigreefunction       age  new_glucose_cat_prediabetes  \\\n",
       "0                    0.485557  1.458321                    -0.953702   \n",
       "1                   -0.363975 -0.186077                    -0.953702   \n",
       "2                    0.624067 -0.099529                    -0.953702   \n",
       "3                   -0.930330 -1.051549                    -0.953702   \n",
       "4                    5.598139 -0.012982                     1.048545   \n",
       "..                        ...       ...                          ...   \n",
       "763                 -0.918018  2.583435                     1.048545   \n",
       "764                 -0.397833 -0.532265                     1.048545   \n",
       "765                 -0.690245 -0.272624                     1.048545   \n",
       "766                 -0.370131  1.198679                     1.048545   \n",
       "767                 -0.474784 -0.878454                    -0.953702   \n",
       "\n",
       "     new_glucose_cat_danger  new_bmi_healthy  new_bmi_overweight  \\\n",
       "0                  1.725995        -0.391488           -0.557086   \n",
       "1                 -0.579376        -0.391488            1.795055   \n",
       "2                  1.725995         2.554360           -0.557086   \n",
       "3                 -0.579376        -0.391488            1.795055   \n",
       "4                 -0.579376        -0.391488           -0.557086   \n",
       "..                      ...              ...                 ...   \n",
       "763               -0.579376        -0.391488           -0.557086   \n",
       "764               -0.579376        -0.391488           -0.557086   \n",
       "765               -0.579376        -0.391488            1.795055   \n",
       "766               -0.579376        -0.391488           -0.557086   \n",
       "767               -0.579376        -0.391488           -0.557086   \n",
       "\n",
       "     new_bmi_obese  new_bloodpressure_hs1  new_bloodpressure_hs2  \\\n",
       "0         0.774597              -0.497943              -0.290113   \n",
       "1        -1.290994              -0.497943              -0.290113   \n",
       "2        -1.290994              -0.497943              -0.290113   \n",
       "3        -1.290994              -0.497943              -0.290113   \n",
       "4         0.774597              -0.497943              -0.290113   \n",
       "..             ...                    ...                    ...   \n",
       "763       0.774597              -0.497943              -0.290113   \n",
       "764       0.774597              -0.497943              -0.290113   \n",
       "765      -1.290994              -0.497943              -0.290113   \n",
       "766       0.774597              -0.497943              -0.290113   \n",
       "767       0.774597              -0.497943              -0.290113   \n",
       "\n",
       "     new_age_cat_1.0  new_age_cat_2.0  \n",
       "0           1.445486        -0.338186  \n",
       "1          -0.691809        -0.338186  \n",
       "2           1.445486        -0.338186  \n",
       "3          -0.691809        -0.338186  \n",
       "4           1.445486        -0.338186  \n",
       "..               ...              ...  \n",
       "763        -0.691809         2.956956  \n",
       "764        -0.691809        -0.338186  \n",
       "765        -0.691809        -0.338186  \n",
       "766         1.445486        -0.338186  \n",
       "767        -0.691809        -0.338186  \n",
       "\n",
       "[760 rows x 17 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7618421052631579"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight='balanced')\n",
    "cross_val_score(lr,X,y,cv=10,n_jobs=-1,scoring=\"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_classifier(best_models,X,y):\n",
    "    voting_clf=VotingClassifier(estimators = [(\"lr\",best_models[\"lr\"]),\n",
    "                                            (\"rf\",best_models[\"rf\"]),\n",
    "                                            (\"xg\",best_models[\"xgb\"])],\n",
    "                              voting='soft',\n",
    "                            weights=[1,1,1])\n",
    "    cv_results = cross_validate(voting_clf,X,y,cv=10,scoring=[\"accuracy\",\"roc_auc\",\"recall\"])\n",
    "    print(f\"accuracy: {cv_results['test_accuracy'].mean()}\")\n",
    "    print(f\"recall: {cv_results['test_recall'].mean()}\")\n",
    "    print(f\"roc_auc: {cv_results['test_roc_auc'].mean()}\")\n",
    "    return voting_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7776315789473685"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(best_models[\"xgb\"],X,y,cv=10,n_jobs=-1,scoring=\"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome\n",
       "0    496\n",
       "1    264\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 sınıfı için ağırlık: 0.7661290322580645\n",
      "1 sınıfı için ağırlık: 1.4393939393939394\n"
     ]
    }
   ],
   "source": [
    "# Sınıf sayıları\n",
    "num_class_0 = 496\n",
    "num_class_1 = 264\n",
    "\n",
    "# Toplam örnek sayısı\n",
    "total_samples = num_class_0 + num_class_1\n",
    "\n",
    "# Ağırlıkları hesapla\n",
    "weight_class_0 = total_samples / (2 * num_class_0)\n",
    "weight_class_1 = total_samples / (2 * num_class_1)\n",
    "\n",
    "print(\"0 sınıfı için ağırlık:\", weight_class_0)\n",
    "print(\"1 sınıfı için ağırlık:\", weight_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.878787878787879"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "496/264 # scale pos weight scale_pos_weight=1.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "num_class_0 = 496\n",
    "num_class_1 = 264\n",
    "\n",
    "# Toplam örnek sayısı\n",
    "total_samples = num_class_0 + num_class_1\n",
    "\n",
    "# Ağırlıkları hesapla\n",
    "weight_class_0 = total_samples / (2 * num_class_0)\n",
    "weight_class_1 = total_samples / (2 * num_class_1)\n",
    "\n",
    "# Y dizisine göre örnek ağırlıklarını oluştur\n",
    "sample_weights = np.where(y == 0, weight_class_0, weight_class_1)\n",
    "\n",
    "# XGBoost modelini eğit\n",
    "dtrain = xgb.DMatrix(X, label=y, weight=sample_weights)\n",
    "param = {'objective': 'binary:logistic'}\n",
    "bst = xgb.train(param, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8787878851164275"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_class_0 = 1.43939394\n",
    "weight_class_1 = 0.76612903\n",
    "\n",
    "scale_pos_weight_value = weight_class_0 / weight_class_1\n",
    "scale_pos_weight_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC: 0.8067352753067037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def xgb_cross_val_score(X, y, params, num_rounds=50, n_folds=10):\n",
    "    # Ağırlıkları hesapla\n",
    "    num_class_0 = np.sum(y == 0)\n",
    "    num_class_1 = np.sum(y == 1)\n",
    "    total_samples = len(y)\n",
    "\n",
    "    weight_class_0 = total_samples / (2 * num_class_0)\n",
    "    weight_class_1 = total_samples / (2 * num_class_1)\n",
    "\n",
    "    # Y dizisine göre örnek ağırlıklarını oluştur\n",
    "    sample_weights = np.where(y == 0, weight_class_0, weight_class_1)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    auc_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        dtrain_weight = sample_weights[train_idx]\n",
    "        dval_weight = sample_weights[val_idx]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X.iloc[train_idx], label=y.iloc[train_idx], weight=dtrain_weight)\n",
    "        dval = xgb.DMatrix(X.iloc[val_idx], label=y.iloc[val_idx], weight=dval_weight)\n",
    "\n",
    "        bst = xgb.train(params, dtrain, num_rounds)\n",
    "        preds_val = bst.predict(dval)\n",
    "        \n",
    "        # AUC değerini hesapla\n",
    "        auc = roc_auc_score(y.iloc[val_idx], preds_val)\n",
    "        auc_scores.append(auc)\n",
    "    \n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "# Örnek parametreler\n",
    "params = {'objective': 'binary:logistic'}\n",
    "\n",
    "# Çapraz doğrulama AUC skorunu al\n",
    "mean_auc = xgb_cross_val_score(X, y, params)\n",
    "print(f\"Mean AUC: {mean_auc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC: 0.8471467527181813\n",
      "Mean Recall: 0.7649572649572649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, recall_score\n",
    "\n",
    "def xgb_cross_val_score(X, y, params, num_rounds=100, n_folds=10):\n",
    "    # Ağırlıkları hesapla\n",
    "    num_class_0 = np.sum(y == 0)\n",
    "    num_class_1 = np.sum(y == 1)\n",
    "    total_samples = len(y)\n",
    "\n",
    "    weight_class_0 = total_samples / (2 * num_class_0)\n",
    "    weight_class_1 = total_samples / (2 * num_class_1)\n",
    "\n",
    "    # Y dizisine göre örnek ağırlıklarını oluştur\n",
    "    sample_weights = np.where(y == 0, weight_class_0, weight_class_1)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    auc_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        dtrain_weight = sample_weights[train_idx]\n",
    "        dval_weight = sample_weights[val_idx]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X.iloc[train_idx], label=y.iloc[train_idx], weight=dtrain_weight)\n",
    "        dval = xgb.DMatrix(X.iloc[val_idx], label=y.iloc[val_idx], weight=dval_weight)\n",
    "\n",
    "        bst = xgb.train(params, dtrain, num_rounds)\n",
    "        preds_val = bst.predict(dval)\n",
    "\n",
    "        # AUC değerini hesapla\n",
    "        auc = roc_auc_score(y.iloc[val_idx], preds_val)\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "        # Recall değerini hesapla\n",
    "        # Öncelikle tahmin edilen sınıfları elde edin (eşik değeri 0.5 olarak alındı)\n",
    "        predicted_classes = np.where(preds_val >= 0.5, 1, 0)\n",
    "        recall = recall_score(y.iloc[val_idx], predicted_classes)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "    return np.mean(auc_scores), np.mean(recall_scores)\n",
    "\n",
    "# Belirtilen parametreler\n",
    "params = {\n",
    "    'booster': 'gblinear',\n",
    "    'reg_lambda': 0.02,\n",
    "    'reg_alpha': 0.01,\n",
    "    'objective': 'binary:logistic'\n",
    "}\n",
    "\n",
    "# Çapraz doğrulama AUC ve Recall skorlarını al\n",
    "mean_auc, mean_recall = xgb_cross_val_score(X, y, params)\n",
    "print(f\"Mean AUC: {mean_auc}\")\n",
    "print(f\"Mean Recall: {mean_recall}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiclass\n",
    "\n",
    "weights = [weight_class_0 if i == 0 else weight_class_1 if i == 1 else weight_class_2 for i in y]\n",
    "dtrain = xgb.DMatrix(X, label=y, weight=weights)\n",
    "\n",
    "Burada weight_class_0, weight_class_1 ve weight_class_2 her sınıf için belirlediğiniz ağırlıklardır\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692307692307692"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = XGBClassifier(n_estimators=100,booster=\"gblinear\",reg_lambda=0.02,reg_alpha=0.01,objective =\"binary:logistic\"\n",
    "                   ,scale_pos_weight=1.88)\n",
    "cross_val_score(xg,X,y,cv=10,n_jobs=-1,scoring=\"recall\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8449379615093902"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(xg,X,y,cv=10,n_jobs=-1,scoring=\"roc_auc\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.556980056980057"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class_counts = np.bincount(y)\n",
    "\n",
    "\n",
    "minority_class = np.argmin(class_counts)  # Azınlık sınıfını bulma\n",
    "majority_class = 1 - minority_class  # Çoğunluk sınıfını bulma\n",
    "\n",
    "# Ağırlıkları ayarlama\n",
    "weights = {minority_class: 5, majority_class: 1}\n",
    "sample_weights = [weights[label] for label in y]\n",
    "\n",
    "# XGBoost modelini bu örnek ağırlıklarıyla eğit\n",
    "xg2 = XGBClassifier(n_estimators=100,booster=\"gblinear\",reg_lambda=0.02,reg_alpha=0.01,objective =\"binary:logistic\"\n",
    "                   ,sample_weight=sample_weights)\n",
    "cross_val_score(xg2,X,y,cv=10,n_jobs=-1,scoring=\"recall\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class_0 = 496\n",
    "num_class_1 = 264\n",
    "\n",
    "# Toplam örnek sayısı\n",
    "total_samples = num_class_0 + num_class_1\n",
    "\n",
    "# Ağırlıkları hesapla\n",
    "weight_class_0 = total_samples / (2 * num_class_0)\n",
    "weight_class_1 = total_samples / (2 * num_class_1)\n",
    "\n",
    "# Y dizisine göre örnek ağırlıklarını oluştur\n",
    "sample_weights = np.where(y == 0, weight_class_0, weight_class_1)\n",
    "sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7769230769230769"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg2 = XGBClassifier(n_estimators=100, booster=\"gblinear\", reg_lambda=0.02, reg_alpha=0.01, objective=\"binary:logistic\")\n",
    "fit_params = {'sample_weight': sample_weights}\n",
    "cross_val_score(xg2, X, y, cv=10, n_jobs=-1, scoring=\"recall\", fit_params=fit_params).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.556980056980057"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg2 = XGBClassifier(n_estimators=100,booster=\"gblinear\",reg_lambda=0.02,reg_alpha=0.01,objective =\"binary:logistic\"\n",
    "                   ,sample_weight=[0,5])\n",
    "cross_val_score(xg2,X,y,cv=10,n_jobs=-1,scoring=\"recall\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7644736842105264\n",
      "recall: 0.5568376068376069\n",
      "roc_auc: 0.8476168963311821\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;,\n",
       "                              LogisticRegression(C=0.1, max_iter=1000,\n",
       "                                                 penalty=&#x27;l1&#x27;,\n",
       "                                                 solver=&#x27;liblinear&#x27;)),\n",
       "                             (&#x27;rf&#x27;,\n",
       "                              RandomForestClassifier(max_depth=6,\n",
       "                                                     min_samples_split=15,\n",
       "                                                     n_estimators=200)),\n",
       "                             (&#x27;xg&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=No...\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=200, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...))],\n",
       "                 voting=&#x27;soft&#x27;, weights=[1, 1, 1])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;,\n",
       "                              LogisticRegression(C=0.1, max_iter=1000,\n",
       "                                                 penalty=&#x27;l1&#x27;,\n",
       "                                                 solver=&#x27;liblinear&#x27;)),\n",
       "                             (&#x27;rf&#x27;,\n",
       "                              RandomForestClassifier(max_depth=6,\n",
       "                                                     min_samples_split=15,\n",
       "                                                     n_estimators=200)),\n",
       "                             (&#x27;xg&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=No...\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=200, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...))],\n",
       "                 voting=&#x27;soft&#x27;, weights=[1, 1, 1])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, max_iter=1000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=6, min_samples_split=15, n_estimators=200)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xg</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=0.1, max_iter=1000,\n",
       "                                                 penalty='l1',\n",
       "                                                 solver='liblinear')),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(max_depth=6,\n",
       "                                                     min_samples_split=15,\n",
       "                                                     n_estimators=200)),\n",
       "                             ('xg',\n",
       "                              XGBClassifier(base_score=None, booster='gblinear',\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=No...\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=200, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...))],\n",
       "                 voting='soft', weights=[1, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier(best_models,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    X,y = diabetes_data_prep()\n",
    "    best_models = hyperparameter_optimization(X,y,scoring=\"roc_auc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
